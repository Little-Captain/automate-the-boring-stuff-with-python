#! python

# 2. å›¾åƒç½‘ç«™ä¸‹è½½
# ç¼–å†™ä¸€ä¸ªç¨‹åºï¼Œè®¿é—®å›¾åƒå…±äº«ç½‘ç«™ï¼Œå¦‚ Flickr æˆ– Imgurï¼ŒæŸ¥æ‰¾ä¸€ä¸ªç±»å‹çš„ç…§ç‰‡
# ç„¶åä¸‹è½½æ‰€æœ‰æŸ¥è¯¢ç»“æœçš„å›¾åƒã€‚å¯ä»¥ç¼–å†™ä¸€ä¸ªç¨‹åºï¼Œè®¿é—®ä»»ä½•å…·æœ‰æŸ¥æ‰¾åŠŸèƒ½çš„å›¾åƒç½‘ç«™

import requests
import os
import sys
import bs4

print('å¼€å§‹ä»»åŠ¡ ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰ğŸ‘‰')

# æœç´¢å…³é”®å­—
keywords = sys.argv[1]

# ç”Ÿæˆæ–‡ä»¶çš„ä¸‹è½½è·¯å¾„
os.makedirs(keywords, exist_ok=True)

baseURL = 'http://www.allitebooks.org/?s=%s' % keywords

res = requests.get(baseURL)
res.raise_for_status()
soup = bs4.BeautifulSoup(res.text, 'html.parser')

imgs = soup.select('img[class="attachment-post-thumbnail wp-post-image"]')
for img in imgs:
    link = img.get('src')
    filename = os.path.join(keywords, os.path.basename(link))
    downloadURL = 'axel -n 3 -a %r -o %r' % (link, filename)
    print('downloading %r' % downloadURL)
    os.system(downloadURL)
    print('downloaded')

print('å®Œæˆä»»åŠ¡ ğŸ‘ŒğŸ‘ŒğŸ‘ŒğŸ‘ŒğŸ‘Œ')
